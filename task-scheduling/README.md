# act3-decrease-n-conquer

Task Scheduling with Random Dependency Graphs (Variable Size Decrease)
Scenario:

A project manager needs to schedule tasks based on their dependencies. The dependency graph is randomly generated by the system. Your task is to:

    Generate a random directed acyclic graph (DAG) representing task dependencies.
    Perform Topological Sorting to determine the correct order of tasks.
    Handle exceptions for cyclic dependencies or invalid graphs.

Instructions:

    Write a program that:
        Generates a random DAG with N tasks and M dependencies (e.g., edges between tasks).
        Implements Topological Sorting using Depth First Search (DFS) to determine the task order.
        Simulates the sorting process step-by-step, showing the tasks being processed in each iteration.
        Handles exceptions for:
            Cyclic dependencies in the graph.
            Invalid data types during graph generation or sorting.
    Allow the user to specify the number of tasks N and dependencies M to generate.
    Test your program with N = 6 and  M = 8, and display the generated graph, topological order, and any exceptions encountered.

Guide Questions:

    1. How will you ensure that the randomly generated graph is a Directed Acyclic Graph (DAG) and does not contain cycles?
       
       Answer: The program ensures the graph is acyclic through the line if(from != to && from < to) inside the generateRandomDAG(). This forces acyclicity because it makes sure that edges are only allowed to go forward wherein it prohibits an edge from going to a higher numbered vertex to a lower numbered vertex (if this was possible, loops could form). For a cycle to form in the first place, a higher numbered vertex would have to be directed to a lower numbered vertex since the vertices are always represented from 0 to N.

    2. What happens if the graph contains a cycle? How will you detect and handle this situation?
       
       Answer: As mentioned in the previous question, the constraints within generateRandomDAG() makes sure that a cycle is never generated. But for the sake of complying with the requirements of the machine problem, the isCyclicUtil() function maintains two separate arrays; (A)visited[] and (B)recursionStack[]. A makes sure to track which vertices have been visited and B tracks the vertices in the current DFS path. If a vertex has been visited (line visited[neighbor] == true) and is currently inside the (recursionStack[neighbor] == true), then this means that there currently exists a path that leads back to a vertex that is still inside the recursionStack[], i.e. there is a loop. If this is the case, then the main() displays 'Error: The generated graph contains a cycle!'.

    3. Why is Topological Sorting an example of variable size decrease ? How does the reduction pattern vary at each step?
       
       Answer: Topological sorting is categorized as variable size decrease because the decrease in problem size per recursive step(in the DFS) varies on how many neighbors a vertex has. A vertex with many neighbors will have a deeper recursion depth than a vertex with few or no neighbors. Thus, in topological sorting, the reduction of the problem size depends on the graph's structure. The program showcases this variability in how tasks are processed - leaf nodes end quickly while highly connected nodes require more processing steps before they can be added to the stack.

    4. How would you modify the program to handle weighted dependencies (e.g., tasks that take different amounts of time to complete)?
       
       Answer: Assuming that the task scheduler would need to account not just for the ordering of the task but also when each task should start and how long(weight = time) the entire project will take:
       
       We would need to incorporate dynamic programming and the critical path method (CPM) algorithm into the current progam in order to determine the minumum possible time needed to complete all tasks. To implement weighted dependencies, we could keep the current topological sort to establish dependency order, but we would initialize all start times to zero before performing critical path analysis and looking for the minimum possible total task duration. 

       
       (1)Forward pass; then for each vertex, we could examine all their respective edges and update the earliest start time(ES) based on the maximum earliest finish time(EF = ES + d, EF - earliest finish, d - duration).

       (2)Backward pass; then from the end of the task list, we can work our way backwards to determine the latest possible time each task could start without delaying(LS = LF - d, LS - latest start, d - duration ).

       (3)Float(slack); we could then determine the float by subtracting the earliest and latest start times(F = LS - ES = LF - EF). For all the tasks that have a float of 0, we add to the critical path.
       
       We can then display the following information, properly accounting for the weight(time) of each dependency.

       - Earliest/latest start times of each task
       - Total project duration (sum of all tasks in the critical path)
       - The float(flexibility) of each task

SOURCES:

https://www.learncpp.com/cpp-tutorial/generating-random-numbers-using-mersenne-twister/

https://www.geeksforgeeks.org/detect-cycle-in-a-graph/

https://github.com/Kumar-laxmi/Algorithms/blob/main/C%2B%2B/Sorting/Topological_Sort.cpp

https://www.youtube.com/watch?v=-TDh-5n90vk

https://en.wikipedia.org/wiki/Critical_path_method

https://www.geeksforgeeks.org/software-engineering-critical-path-method/

https://tiemchart.com/blogs/training/forward-pass-and-backward-pass/